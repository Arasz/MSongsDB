<div class="post">
<h2>Tasks</h2><p>
Our main goal is to provide the data because researchers will know what 
they want to do with it. That being said, we give some information regarding
typical MIR tasks below. We hope to provide snippets of code and benchmarks
results to help you getting started. If you want to provide additional
information / link to your code / new results, please send us an email!
<ol>
<li><a href="#segmentation">Segmentation</a></li>
<li><a href="#automatictagging">Automatic tagging</a></li>
<li><a href="#yearrecognition">Year recognition</a></li>
<li><a href="#imputation">Imputation of missing data</a></li>
<li><a href="#nameanalysis">Artist name, release, song title analysis</a></li>
</ol>
<a name='segmentation'><h3>Segmentation</h3></a>
The goal is to divide a song into meaningfull segments, usually
chorus / verse / bridge or similar. The Echo Nest analysis provides
some estimated segments, but you can use basic Echo Nest features
(chroma or MFCC-like features) on the beat level with your own
algorithms.<br>
Here we use UCSD <a href="http://cosmal.ucsd.edu/cal/projects/segment/DTMsegment_v1.0.tar">code</a> from this
<a href="http://cosmal.ucsd.edu/cal/projects/segment/">project</a>.
We estimate the sections and compare with Echo Nest estimation.<p>

<a name='automatictagging'><h3>Automatic tagging</h3></a>
<a href="http://scholar.google.com/scholar?q=ismir+automatic+tagging">
Automatic tagging</a> of audio is the association of appropriate
keywords to some specific sound segment. In MIR research, this class
can encompass "music genre recognition", "mood detection", and
some aspects of "audio scene analysis". This dataset provides
audio features and tags, therefore is a good set to compare algorithms
on such tasks.<p>

<a name='yearrecognition'><h3>Year recognition</h3></a>
This is a simple supervised task easy to set up with the dataset.
From audio features, probably "segments_timbre", and possibly some
other information like "energy", "danceability", etc, try to predict
the year or decade when this song was released.<p>

<a name='imputation'><h3>Imputation of missing data</h3></a>
Imputation of missing data in time series is
<a href="http://scholar.google.com/scholar?hl=en&q=interpolation+missing+values+audio+data">well-known</a>.
Recently, we have studied imputation of beat-aligned
chroma features ???? using Echo Nest data. The Million Song
Dataset can easily be use to further experiment with this task.
Code available here ????.<p>

<a name='nameanalysis'><h3>Artist name, release, song title analysis</h3></a>
Many analysis of the metadata is possible. How do the words of the artist
names or their song titles cluster? Can we predict tags based on that, or
is the clustering similar? What is "the most typical song title"
imagineable.<p>

</div>
