<div class="post">
<h2>FAQ</h2><br>
<a href='#whatisindataset'>What is in the dataset?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#stats'>Stats</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#fields'>Fields description</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#mbrainz'>MusicBrainz data</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#termsmbtags'>Terms versus mbtags?</a><br>
<a href='#gettingdataset'>How to get the dataset?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#notapi'>Why is it not an API?</a><br>
<a href='#whatisformat'>What is the format?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#hdfwhat'>HDF what?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#aggregate'>song / aggregate / summary files</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#utf8'>Why strings do not display properly?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#visualize'>How can I visualize a file?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#filepaths'>What are the file paths?</a><br>
<a href='#whatcanido'>What can I do with this data?</a><br>
<a href='#howtoorganize'>How do I get it organized?</a><br>
<a href='#howcreated'>How was the dataset created?</a><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href='#myaudio'>Can I add my audio to the dataset?</a><br>
<a href='#whatlicense'>What is the licensing?</a><br>
<a href='#website'>Why this website doesn't load sometimes?</a><br>
<a href='#wherehelp'>Where can I get help?</a><br>
<a href='http://thefullfool.files.wordpress.com/2010/09/wheres-waldo1.jpg'>Where is Waldo?</a><br>
<a href='#getinvolved'>How can I get involved?</a><p>

<a name='whatisindataset'><h3>What is in the dataset?</h3></a>
Good question, a lot of things. Mostly, almost all information
provided by the Echo Nest API which encompasses both metadata
and audio analysis. Each file is for one track which corresponds
to one song, one release and one artist. All the information about
these four items (track, song, release, artist) are in every file
(yes, there is redundancy).<br>
For an in depth look, go to the following
section describing all <a href='#fields'>fields</a> you will find
in one song file. Note that the data is quite complete, but some fields
might be missing for some songs. For instance, we don't know the location
for all artists.<p>

<a name='stats'><h3>Stats</h3></a>
<ol>
<li>1.000.000 songs / files</li>
<li>273 GB of data</li>
<li>44.745 unique artists</li>
<li>7.643 unique terms (Echo Nest tags)</li>
<li>2.321 unique musicbrainz tags</li>
<li>2.201.916 asymmetric similarity relationships</li>
<li>11 pastries lost in a related hackday</li>
</ol>
<p>

<a name='fields'><h3>Fields description</h3></a>
Below are a list of all fields available in the files of the dataset.
Another reference is the code:
<a href="https://github.com/tb2332/MSongsDB/blob/master/PythonSrc/display_song.py">
display_song.py</a>. If a field is displayed, the field exists
and there should be a getter for it (if we forgot some in matlab or java,
please let us know).
For the analysis field, we suggest you first read the Echo Nest
<a href='http://developer.echonest.com/docs/v4/_static/AnalyzeDocumentation_2.2.pdf'>analyze documentation</a>.

<table border="1">
<tr>
<th>Field name</th>
<th>Type</th>
<th>Description</th>
<th>Link</th>
</tr>
<tr>
<td>analysis sample rate</td>
<td>float</td>
<td>sample rate of the audio used</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>artist 7digitalid</td>
<td>int</td>
<td>ID from 7digital.com or -1</td>
<td><a href='http://www.7digital.com/'>url</a></td>
</tr>
<tr>
<td>artist familiarity</td>
<td>float</td>
<td>algorithmic estimation</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#familiarity'>url</a></td>
</tr>
<tr>
<td>artist hotttnesss</td>
<td>float</td>
<td>algorithmic estimation</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#hotttnesss'>url</a></td>
</tr>
<tr>
<td>artist id</td>
<td>string</td>
<td>Echo Nest ID</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#search'>url</a></td>
</tr>
<tr>
<td>artist latitude</td>
<td>float</td>
<td>latitude</td>
<td></td>
</tr>
<tr>
<td>artist location</td>
<td>string</td>
<td>location name</td>
<td></td>
</tr>
<tr>
<td>artist longitude</td>
<td>float</td>
<td>longitude</td>
<td></td>
</tr>
<tr>
<td>artist mbid</td>
<td>string</td>
<td>ID from musicbrainz.org</td>
<td><a href='http://musicbrainz.org/'>url</a></td>
</tr>
<tr>
<td>artist mbtags</td>
<td>array string</td>
<td>tags from musicbrainz.org</td>
<td><a href='http://musicbrainz.org/'>url</a></td>
</tr>
<tr>
<td>artist mbtags count</td>
<td>array int</td>
<td>tag counts for musicbrainz tags</td>
<td><a href='http://musicbrainz.org/'>url</a></td>
</tr>
<tr>
<td>artist name</td>
<td>string</td>
<td>artist name</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#search'>url</a></td>
</tr>
<tr>
<td>artist playmeid</td>
<td>int</td>
<td>ID from playme.com, or -1</td>
<td><a href='http://www.playme.com/'>url</a></td>
</tr>
<tr>
<td>artist terms</td>
<td>array string</td>
<td>Echo Nest tags</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#terms'>url</a></td>
</tr>
<tr>
<td>artist terms freq</td>
<td>array float</td>
<td>Echo Nest tags freqs</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#terms'>url</a></td>
</tr>
<tr>
<td>artist terms weight</td>
<td>array float</td>
<td>Echo Nest tags weight</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#terms'>url</a></td>
</tr>
<tr>
<td>audio md5</td>
<td>string</td>
<td>audio hash code</td>
<td></td>
</tr>
<tr>
<td>bars confidence</td>
<td>array float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>bars start</td>
<td>array float</td>
<td>beginning of bars, usually on a beat</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>beats confidence</td>
<td>array float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>beats start</td>
<td>array float</td>
<td>result of beat tracking</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>danceability</td>
<td>float</td>
<td>algorithmic estimation</td>
<td></td>
</tr>
<tr>
<td>duration</td>
<td>array float</td>
<td>in seconds</td>
<td></td>
</tr>
<tr>
<td>end of fade in</td>
<td>float</td>
<td>seconds at the beginning of the song</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>energy</td>
<td>float</td>
<td>energy from listener point of view</td>
<td></td>
</tr>
<tr>
<td>key</td>
<td>int</td>
<td>key the song is in</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>key confidence</td>
<td>float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>loudness</td>
<td>float</td>
<td>overall loudness in dB</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>mode</td>
<td>int</td>
<td>major or minor</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>mode confidence</td>
<td>float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>release</td>
<td>string</td>
<td>album name</td>
<td></td>
</tr>
<tr>
<td>release 7digitalid</td>
<td>int</td>
<td>ID from 7digital.com or -1</td>
<td><a href='http://www.7digital.com/'>url</a></td>
</tr>
<tr>
<td>sections confidence</td>
<td>array float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>sections start</td>
<td>array float</td>
<td>largest grouping in a song, e.g. verse</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments confidence</td>
<td>array float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments loudness max</td>
<td>array float</td>
<td>max dB value</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments loudness max time</td>
<td>array float</td>
<td>time of max dB value, i.e. end of attack</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments loudness max start</td>
<td>array float</td>
<td>dB value at onset</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments pitches</td>
<td>2D array float</td>
<td>chroma feature, one value per note</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments start</td>
<td>array float</td>
<td>musical events, ~ note onsets</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>segments timbre</td>
<td>2D array float</td>
<td>texture features (MFCC+PCA-like)</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>similar artists</td>
<td>array string</td>
<td>Echo Nest artist IDs (sim. algo. unpublished)</td>
<td><a href='http://developer.echonest.com/docs/v4/artist.html#similar'>url</a></td>
</tr>
<tr>
<td>song hotttnesss</td>
<td>float</td>
<td>algorithmic estimation</td>
<td></td>
</tr>
<tr>
<td>song id</td>
<td>string</td>
<td>Echo Nest song ID</td>
<td></td>
</tr>
<tr>
<td>start of fade out</td>
<td>float</td>
<td>time in sec</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>tatums confidence</td>
<td>array float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>tatums start</td>
<td>array float</td>
<td>smallest rythmic element</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>tempo</td>
<td>float</td>
<td>estimated tempo in BPM</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>time signature</td>
<td>int</td>
<td>estimate of number of beats per bar, e.g. 4</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>time signature confidence</td>
<td>float</td>
<td>confidence measure</td>
<td><a href='http://developer.echonest.com/docs/v4/track.html'>url</a></td>
</tr>
<tr>
<td>title</td>
<td>string</td>
<td>song title</td>
<td></td>
</tr>
<tr>
<td>track id</td>
<td>string</td>
<td>Echo Nest track ID</td>
<td></td>
</tr>
<tr>
<td>track 7digitalid</td>
<td>int</td>
<td>ID from 7digital.com or -1</td>
<td><a href='http://www.7digital.com/'>url</a></td>
</tr>
<tr>
<td>year</td>
<td>int</td>
<td>song release year from MusicBrainz or 0</td>
<td><a href='http://musicbrainz.org/'>url</a></td>
</tr>
</table><br>
<p>

<a name='mbrainz'><h3>MusicBrainz data</h3></a>
Fields 'year', 'artist_mbtags' and 'artist_mbtags_count'
have been extracted from
the <a href="http://musicbrainz.org/">MusicBrainz</a>. We used a local copy 
of the <a href="http://wiki.musicbrainz.org/Server_Setup">
server</a>, our version is this 
<a href="http://svn.musicbrainz.org/mb_server/branches/RELEASE_20090524-BRANCH/">
branch</a>, the data dumps were of December 4th, 2010.
Note that the field 'artist_mbid' is provided by the EchoNest API.
<p>

<a name='termsmbtags'><h3>Terms versus mbtags?</h3></a>
Terms are the Echo Nest tags. They can come from a number of places, but
mostly blogs as far as we understand it.<br>
Mbtags are the musicbrainz tags, applied by humans to a particular artist.
This explains why there are less of them (see 'mbtags_count'), but they
are usually very clean and informative. For instance, if you want to
create a genre recognition task where classes are mutually exclusive,
mbtags are probably more reliable then terms.<p>

<a name='gettingdataset'><h3>How to get the dataset?</h3></a>
See tab <a onClick="clientSideInclude('left','left_getting.txt');" href='#'>Getting the dataset</a>.
A subset is also available there to quickly get you started.
<p>

<a name='notapi'><h3>Why is it not an API?</h3></a>
API have a lot of merit, and most of this dataset was built using
the Echo Nest API (with unlimited access). But APIs have not
solved all research problems, and there is a place for such a fixed
dataset. Everyone gets the same data and can report results on the same
songs and features. Also, it facilitates the download. It is not because
an API exists that one gets through the trouble of downloading a million
songs.<br>
That being said, this dataset and API can be complementary. This is why
we made sure we provided enough metadata such as musicbrainz ID so everyone
can link this data to other existing resources.<p>

<a name='whatisformat'><h3>What is the format?</h3></a>
Each file represents one track with all the related information
(artist information, release information, audio analysis of the track, etc).
Usually one track is one song, though we can not guarantee that some
songs are not duplicated. Also, remember the some sons are released
many times with slight differences.<br>
The actual file format of each file is <a href='#hdfwhat'>HDF5</a>.
A schema of the inner organization of a HDF5 song file can be found
<a href="files/FileSchema.pdf">here</a>.
<p>

<a name='hdfwhat'><h3>HDF what?</h3></a>
HDF5! Why? Because! (regarding this, all complains should definitely
go to tb2332@columbia.edu). In short, <a href="http://www.hdfgroup.org/HDF5/">HDF5</a> 
is a format developped by NASA to handle 1) large 2) heterogeneous 3)
hierarchical datasets. The data can be compressed (10%-15% more that matfiles), 
and the I/O speed is still impressive. Also note that the core library comes free of charge and
wrappers exist in most languages (see "code" section).<br>
Is is perfect? No. Does it make more sense that 1M zipped json files or
matfiles? Yes. 
Note that the new matfile format (v7.3) is 
<a href="http://mloss.org/community/blog/2009/nov/19/matlabtm-73-file-format-is-actually-hdf5-and-can-b/">
actually HDF5</a>.<br>
Still not happy? Here is a 
<a href="https://github.com/tb2332/MSongsDB/blob/master/PythonSrc/hdf5_to_matfile.py">python code</a> 
or a 
<a href="https://github.com/tb2332/MSongsDB/blob/master/MatlabSrc/hdf5_to_matfile.m">matlab code</a> 
to transform the data into matfiles (the latter is less tested, strings seem wrongly encoded).<p>


<a name='aggregate'><h3>song / aggregate / summary files</h3></a>
We usually use song file to refer to the typical HDF5 file that contains
the information for only one song. An aggregate file is also an HDF5 file,
but that contains the information of many songs. It is usefull if you do
I/O intensive experiments, as it reduce the number of open/close file
operations you need to perform. A summary file is similar to an
aggregate file, but contains just the metadata, i.e. we remove all
the big tables like the analysis (bars, beats, segments, ...).
Usefull if you want to quickly search the metadata, a lot of space is
saved!<br>
Note on summary files, if you're using the code 
<a href="https://github.com/tb2332/MSongsDB/blob/master/PythonSrc/display_song.py">
display_song.py</a>, you need the '-summary' flag to tell the code 
that some getters won't find their field, e.g. bars_start.<br>
The dataset you received should contain one million song files.
You can create aggregate and/or summary files using the python scripts.
<p>


<a name='utf8'><h3>Why strings do not display correctly?</h3></a>
All data was downloaded in utf-8 format and was saved in the HDF5
file in utf-8 format. Does it mean every name / release / title
should display correctly if you set your display to utf-8? We sure
hope so, but in practice some string with uncommon elements will never 
be correctly recorded. In particular, it seems difficult to tell MATLAB
to read HDF5 as UTF-8 instead of Unicode. If you have a work-around, let
us know!<br>
Conclusion: use the strings like titles and artist
names as indications, the real identifiers should be the musicbrainz ID
or the echonest ID.<p>

<a name='visualize'><h3>How can I visualize a file?</h3></a>
We mean quickly glance at the content of a file.
Once again, it depends on the language you want to use, and you
need the HDF5 library installed (see "code" section). In python
(with <a href='http://www.pytables.org/'>pytables</a> installed), 
use <a href="https://github.com/tb2332/MSongsDB/blob/master/PythonSrc/display_song.py">
display_songs.py</a>. In Java, you can use the great tool 
<a href=http://www.hdfgroup.org/hdf-java-html/hdfview/index.html>HDFVIEW</a>.
MATLAB should also let you see the content, try opening the file.
<p>

<a name='filepaths'><h3>What are the file paths?</h3></a>
We could not put a million files in one folder. Even a few thousands
can slow your operating system significantly. We used the track ID
from the Echo Nest which can be viewed as a hash code. It is always
TR+LETTERS+LETTERS&NUMBERS. The path is the 3rd, 4th, 5th letters
from the track ID, the file itself is named after its track ID + the
extension ".h5".<p>

<a name='whatcanido'><h3>What can I do with this data?</h3></a>
Surprise us! But you might want a take a look at the "tasks"
section to get inspired. You will also find there some snippets
of code that let's you easily crawl through the whole data.<p>

<a name='howtoorganize'><h3>How do I get it organized?</h3></a>
Gordon! more to come on this.<br>
We also created (and you have the code to recreate / adapt them)
three SQLite databases (available 
<a href="http://www.ee.columbia.edu/~thierry/track_metadata.db">here</a>, 
<a href="http://www.ee.columbia.edu/~thierry/artist_term.db">here</a> and
<a href="http://www.ee.columbia.edu/~thierry/artist_similarity.db">here</a>). 
The
first one gives most metadata per track. It is usefull, for
instance, to get all tracks from the same artist as some song file.
The second one gives terms per artist. You can use it to get the
full list of artists, full list of tags, the usage of tags, etc.
The third one summarizes artist similarity. In particular, it only lists
artists that actually are in the dataset.<br>
For demos using this databases with SQL queries in python, see
demo_*.py in <a href="https://github.com/tb2332/MSongsDB/tree/master/Tasks_Demos/SQLite">
SQLite folder</a>.
<p>

<a name='howcreated'><h3>How was the dataset created?</h3></a>
Using the Echonest API and some info from a local copy of the
musicbrainz server. Data was downloaded during December 2010.
Choosing a million songs is surprisingly challenging. We followed these steps:
<ol>
<li>Get the most 'familiar' artists according to Echo Nest, download as many
songs from them as possible</li>
<li>Get the 200 top terms from Echo Nest, use each term as a descriptor to 
find 100 artists, download as many songs as possible</li>
<li>Get the songs and artists from the CAL500 dataset</li>
<li>Get 'extreme' songs from the Echo Nest search params, e.g. songs
with highest energy, lowest energy, tempo, song hotttnesss, ...</li>
<li>Random walk on similar artists starting from the 100 most familiar ones</li>
</ol>
The number of songs was approximately 8950 after step 1), step 3) added
around 15000 songs, and we add approx. 500000 songs before starting step 5.
For more techincal details, see "dataset creation" in "code" section.<p>

<a name='myaudio'><h3>Can I add my audio to the dataset?</h3></a>
In the sense that you want your audio file to be analyzed and put in
HDF5 format as the rest of the dataset, the answer is mostly yes,
the following python
<a href="https://github.com/tb2332/MSongsDB/blob/master/PythonSrc/enpyapi_to_hdf5.py">code</a>
should do the trick. Note that it uses pyechonest, and to have the
full data ('year','mbtags' and 'mbtags_count'), you need a local
musicbrainz server.<br>
The code is not perfect for the following reasons: 1) it is unclear what
happens if the song is not recognized by the Echo Nest fingerprinter and
2) even if it is recognized, if you upload audio associated with a song 
in the dataset, there is no guarantee you get the same track ID.<p>

<a name='whatlicense'><h3>What is the licensing?</h3></a>
The Echo Nest data is released under the same 
<a href="http://developer.echonest.com/terms">terms of use</a> 
as their API.
If you are a researcher and want to publish results on the dataset,
you are fine.
If you are a company and are concerned about experimenting on the
dataset, send an email to The Echo Nest.<br>
Regarding the MusicBrainz data contained in the dataset,
the track 'year' is under 
<a href="http://creativecommons.org/licenses/publicdomain/">
public domain</a> and the 'tags' and 'tag count' are under
<a href="http://creativecommons.org/licenses/by-nc-sa/2.0/">
Attribution-NonCommercial-ShareAlike 2.0</a> license.<br>
The code is released under GNU Public License.<p> 

<a name='website'><h3>Why this website doesn't load sometimes?</h3></a>
You need to enable javascript. We also use a 'non-official' javascript
function that loads external HTML from the client side.
This should be supported on the following recent browsers: IE, firefox,
chrome, safari, opera. If you still have issues, send us an email.<br>
Our university server isn't perfect either.<p>

<a name='wherehelp'><h3>Where can I get help?</h3></a>
There is no mailing or user blog so far. Simply contact one
of the creator at LabROSA or the Echo Nest, see the "contact us"
section. <a href="mailto:tb2332@columbia.edu">Thierry Bertin-Mahieux</a> 
is a good first try.<p>

<a name='getinvolved'><h3>How can I get involved?</h3></a>
Simple! Use the dataset and share your code. We will be happy
to put it on this website. You can also share this website using
the buttons on the right menu.
Then, put on your website the list of songs 
(e.g. their Echo Nest ID) you use when you publish something.
With a simple list of IDs in a text file, one can recreate a test
set in a few minutes, and compare results with his own algorithm!
Finally, talk to other researchers about using larger datasets.
<a href="http://marsyas.info/download/data_sets">GZTAN genre collection</a>
was amazingly useful, but we need to move on.
<p>

</div>

